import torch
import torchvision.transforms as T
import matplotlib.pyplot as plt
import numpy as np
from PIL import Image
from torch.nn import functional as F
from torchvision.models import resnet18
from scipy.ndimage import label, center_of_mass
from scipy.optimize import linear_sum_assignment
import requests
from io import BytesIO

# Load pretrained ResNet
model = resnet18(weights='IMAGENET1K_V1').eval()

# Download and preprocess image
url = "https://www.nps.gov/lacl/learn/nature/images/Image-w-cred-cap_-1200w-_-Brown-Bear-page_-brown-bear-in-fog_2.jpg?maxwidth=1300&maxheight=1300&autorotate=false"
img = Image.open(BytesIO(requests.get(url).content)).convert('RGB')
transform = T.Compose([T.Resize((224, 224)), T.ToTensor()])
input_tensor = transform(img).unsqueeze(0)

# Hooks for Grad-CAM
feature_maps, gradients = None, None
def forward_hook(module, input, output): global feature_maps; feature_maps = output
def backward_hook(module, grad_in, grad_out): global gradients; gradients = grad_out[0]
model.layer4[1].conv2.register_forward_hook(forward_hook)
model.layer4[1].conv2.register_full_backward_hook(backward_hook)

def generate_cam(input_tensor):
    model.zero_grad()
    output = model(input_tensor)
    class_idx = output.argmax(dim=1).item()
    output[0, class_idx].backward()
    weights = gradients.mean(dim=[2, 3], keepdim=True)
    cam = (weights * feature_maps).sum(dim=1, keepdim=True)
    cam = F.relu(cam)
    cam = F.interpolate(cam, size=(224, 224), mode='bilinear', align_corners=False)
    cam = cam.squeeze().detach().numpy()
    return (cam - cam.min()) / (cam.max() - cam.min())

def apply_transform(image, kind):
    if kind == 'rotate':
        return T.functional.rotate(image, 10)
    elif kind == 'crop':
        return T.Resize((224, 224))(T.CenterCrop(200)(image))
    return image

def get_mask_and_centroids(cam, threshold=0.5):
    binary_mask = cam > threshold
    labeled, _ = label(binary_mask)
    centers = center_of_mass(binary_mask, labeled, range(1, np.max(labeled)+1)) if np.max(labeled) > 0 else []
    return binary_mask, centers

def ospa(X, Y, c=0.5, p=2):
    m, n = len(X), len(Y)
    if m == 0 or n == 0: return c * max(m, n)
    cost_matrix = np.array([[min(np.linalg.norm(np.array(x)-np.array(y), ord=p), c)**p for y in Y] for x in X])
    row_ind, col_ind = linear_sum_assignment(cost_matrix)
    loc_error = cost_matrix[row_ind, col_ind].sum()
    card_penalty = (c**p) * abs(m - n)
    return (loc_error + card_penalty)**(1/p)

# Process and show
trans_img = apply_transform(img, 'rotate')
trans_tensor = transform(trans_img).unsqueeze(0)
cam_orig = generate_cam(input_tensor)
cam_trans = generate_cam(trans_tensor)
mask_orig, centers_orig = get_mask_and_centroids(cam_orig)
mask_trans, centers_trans = get_mask_and_centroids(cam_trans)
score = ospa(centers_orig, centers_trans)

# Visualization
fig, axes = plt.subplots(3, 3, figsize=(14, 12))
axes[0, 0].imshow(img); axes[0, 0].set_title("Original Image"); axes[0, 0].axis('off')
axes[0, 1].imshow(trans_img); axes[0, 1].set_title("Transformed Image"); axes[0, 1].axis('off')
axes[0, 2].axis('off')

axes[1, 0].imshow(cam_orig, cmap='jet'); axes[1, 0].set_title("Original CAM"); axes[1, 0].axis('off')
axes[1, 1].imshow(cam_trans, cmap='jet'); axes[1, 1].set_title("Transformed CAM"); axes[1, 1].axis('off')
axes[1, 2].imshow(np.abs(cam_orig - cam_trans), cmap='hot'); axes[1, 2].set_title("CAM Difference"); axes[1, 2].axis('off')

axes[2, 0].imshow(mask_orig, cmap='gray'); axes[2, 0].set_title("Original Mask"); axes[2, 0].axis('off')
axes[2, 1].imshow(mask_trans, cmap='gray'); axes[2, 1].set_title("Transformed Mask"); axes[2, 1].axis('off')
axes[2, 2].imshow(mask_orig != mask_trans, cmap='gray'); axes[2, 2].set_title("Mask Discrepancy"); axes[2, 2].axis('off')

plt.suptitle(f"OSPA Discrepancy Score: {score:.4f}", fontsize=16)
plt.tight_layout()
plt.show()
